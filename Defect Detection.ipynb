{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":2266446,"sourceType":"datasetVersion","datasetId":1364422}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')\n\nroot_dir = '/content/drive/MyDrive/PCB_defect_detection'","metadata":{"id":"SrUaydq-uQOb","outputId":"a843814a-6001-4f33-dd56-c831c5ddd107"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U ultralytics","metadata":{"id":"46nXzU39tjyY","outputId":"5b1d7b54-ea67-4882-da8d-c750c81371cd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport os\nimport shutil\nimport random\nimport xml.etree.ElementTree as ET\nimport yaml\nfrom pathlib import Path\nfrom collections import Counter\n\nfrom ultralytics import YOLO\nfrom sklearn.model_selection import KFold","metadata":{"id":"eOovCs5iqe56"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Explore Dataset","metadata":{"id":"08hK9kjPrSyP"}},{"cell_type":"code","source":"dataset_dir = os.path.join(root_dir, 'PCB_DATASET')\n\nfor root, dirs, files in os.walk(dataset_dir):\n   for name in dirs:\n      print(os.path.join(root, name))","metadata":{"id":"EPtQ1vRDrQff","outputId":"b1ed1ffe-ba68-4b51-95f3-c534e26a7995"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_files_in_folder(folder_path):\n    # Get list of all files in the folder\n    files = os.listdir(folder_path)\n\n    # Count the number of files\n    num_files = len(files)\n\n    return num_files","metadata":{"id":"ZG4j3UFnWpjH"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"subfolders = ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']\n\nimages_dir = os.path.join(dataset_dir, 'images')\nannot_dir = os.path.join(dataset_dir, 'Annotations')\n\nfor subfolder in subfolders:\n    images_path = os.path.join(images_dir, subfolder)\n    annot_path = os.path.join(annot_dir, subfolder)\n\n    print(f'{subfolder:<15} \\t\\\n            {count_files_in_folder(images_path)} images \\t\\\n            {count_files_in_folder(annot_path)} annotations')","metadata":{"id":"1_YcUxaUVVCn","outputId":"d5dec9e4-56af-435d-e395-7769ed98cae1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create annotaton dataset","metadata":{"id":"u_srlgxrhQ2_"}},{"cell_type":"code","source":"def parse_xml(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    data = []\n\n    filename = root.find('filename').text\n    width = int(root.find('size/width').text)\n    height = int(root.find('size/height').text)\n\n    for obj in root.findall('object'):\n        name = obj.find('name').text\n        xmin = int(obj.find('bndbox/xmin').text)\n        ymin = int(obj.find('bndbox/ymin').text)\n        xmax = int(obj.find('bndbox/xmax').text)\n        ymax = int(obj.find('bndbox/ymax').text)\n\n        data.append({\n            'filename': filename,\n            'width': width,\n            'height': height,\n            'class': name,\n            'xmin': xmin,\n            'ymin': ymin,\n            'xmax': xmax,\n            'ymax': ymax\n        })\n\n    return data","metadata":{"id":"IqYGOYZKkiZp"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List to store parsed data from all XML files\nall_data = []\n\n# Recursively traverse subdirectories\nfor root, dirs, files in os.walk(annot_dir):\n    for name in files:\n        if name.endswith('.xml'):\n            xml_path = os.path.join(root, name)\n            all_data.extend(parse_xml(xml_path))","metadata":{"id":"pP9lRfh6kmlP"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create DataFrame from the parsed data\nannot_df = pd.DataFrame(all_data)\nannot_df.head()","metadata":{"id":"zBb3srZZlfld","outputId":"42bd5de0-7ce7-4a6d-b69d-7e93f381031c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization","metadata":{"id":"PxrWDtWShUVx"}},{"cell_type":"code","source":"def get_subfolder(image_name):\n    if 'missing' in image_name.split('_'):\n        return 'Missing_hole'\n    if 'mouse' in image_name.split('_'):\n        return'Mouse_bite'\n    if 'open' in image_name.split('_'):\n        return 'Open_circuit'\n    if 'short' in image_name.split('_'):\n        return 'Short'\n    if 'spur' in image_name.split('_'):\n        return 'Spur'\n    if 'spurious' in image_name.split('_'):\n        return 'Spurious_copper'","metadata":{"id":"VEWjyB9Q1t0R"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_annotations(image_name, images_dir, annot_df, is_subfolder=False):\n    # Construct path for image\n    if is_subfolder:\n        image_path = os.path.join(images_dir, get_subfolder(image_name), image_name)\n    else:\n        image_path = os.path.join(images_dir, image_name)\n\n\n    # Read image\n    image = cv2.imread(image_path)\n\n    # Filter annotations for the current image\n    annotations = annot_df[annot_df['filename'] == image_name]\n\n    # Draw bounding boxes on the image\n    for _, annot in annotations.iterrows():\n        xmin, ymin, xmax, ymax = annot['xmin'], annot['ymin'], annot['xmax'], annot['ymax']\n        class_label = annot['class']\n\n        # Check if confidence column exists\n        confidence = annot.get('confidence')\n        if confidence is not None:\n            class_label += f\" ({confidence:.2f})\"\n\n        color = (255, 255, 255)\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 3)\n\n        # Add background to the text\n        text_size = cv2.getTextSize(class_label, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 2)[0]\n        cv2.rectangle(image, (xmin, ymin - text_size[1] - 5),\n                             (xmin + text_size[0], ymin - 1), color, -1)\n\n        # Add text\n        cv2.putText(image, class_label, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n\n    # Convert BGR image to RGB (Matplotlib expects RGB)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Plot the image with annotations\n    plt.figure(figsize=(18, 10))\n    plt.imshow(image_rgb)\n    plt.axis('off')\n    plt.title('Annotations')\n    plt.text(10, image_rgb.shape[0] + 100, f'Image: {image_name}',\n             color='black', fontsize=11, ha='left')\n    plt.show()\n\n    return image\n","metadata":{"id":"PwO9BLFs9XNv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_name = '04_short_03.jpg'\nvisualize_annotations(image_name, images_dir, annot_df, is_subfolder=True);","metadata":{"id":"_kHrWBvCtN-7","outputId":"6e1c8f61-249e-4ad4-e7a4-f9ef19f7aa8b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset preprocessing","metadata":{"id":"FP4z90JkrirL"}},{"cell_type":"code","source":"def resize_images(input_dir, output_dir, target_size=(640, 640)):\n    # Create the output directory if it doesn't exist\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Traverse through the subfolders in the input folder\n    for root, _, files in os.walk(input_dir):\n        for file in files:\n            # Check if the file is an image\n            if file.lower().endswith(('.jpg')):\n                # Read the image\n                image_path = os.path.join(root, file)\n                image = cv2.imread(image_path)\n\n                # Resize the image\n                resized_image = cv2.resize(image, target_size)\n\n                # Save the resized image to the output folder\n                output_path = os.path.join(output_dir, file)\n                cv2.imwrite(output_path, resized_image)\n\nresized_img_dir = os.path.join(dataset_dir, 'images_resized')\nresize_images(images_dir, resized_img_dir)","metadata":{"id":"ox9vWEkQdC5z"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def resize_annotations(annot_df, target_size=(640, 640)):\n    all_data = []\n\n    # Iterate through the annotation DataFrame\n    for index, row in annot_df.iterrows():\n\n        # Resize the bounding box coordinates\n        width_ratio = target_size[0] / row['width']\n        height_ratio = target_size[1] / row['height']\n\n        resized_xmin = int(row['xmin'] * width_ratio)\n        resized_ymin = int(row['ymin'] * height_ratio)\n        resized_xmax = int(row['xmax'] * width_ratio)\n        resized_ymax = int(row['ymax'] * height_ratio)\n\n        # Update the all data list with resized annotations\n        all_data.append({\n            'filename': row['filename'],\n            'width': target_size[0],\n            'height': target_size[1],\n            'class': row['class'],\n            'xmin': resized_xmin,\n            'ymin': resized_ymin,\n            'xmax': resized_xmax,\n            'ymax': resized_ymax\n        })\n\n    annot_df_resized = pd.DataFrame(all_data)\n    return annot_df_resized\n\nannot_df_resized = resize_annotations(annot_df)\nannot_df_resized.head()","metadata":{"id":"3BOM8HFBh5vC","outputId":"2eec901f-b900-4d06-e0fe-ef3e3683ad19"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split dataset","metadata":{"id":"5BiCIHYpCX0b"}},{"cell_type":"code","source":"# Create the output directory\noutput_dir = os.path.join(dataset_dir, 'output')\nos.makedirs(output_dir, exist_ok=True)","metadata":{"id":"s73xb9aafX6Q"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert annotation DataFrame into YOLO labels\n# YOLO format: <class_index> <x_center> <y_center> <width> <height>\ndef convert_to_yolo_labels(annotation_df, classes, target_size=(640, 640)):\n    yolo_labels = []\n\n    for _, annot in annotation_df.iterrows():\n        filename = annot['filename']\n        width, height = annot['width'], annot['height']\n        class_name = annot['class']\n        xmin, ymin, xmax, ymax = annot['xmin'], annot['ymin'], annot['xmax'], annot['ymax']\n\n        # Convert bounding box coordinates to YOLO format\n        x_center = (xmin + xmax) / (2 * width)\n        y_center = (ymin + ymax) / (2 * height)\n        bbox_width = (xmax - xmin) / width\n        bbox_height = (ymax - ymin) / height\n\n        class_index = classes.index(class_name)\n\n        # Append to YOLO labels list\n        yolo_labels.append((filename, class_index, x_center, y_center, bbox_width, bbox_height))\n\n    return yolo_labels\n\n\nclasses = ['missing_hole', 'mouse_bite', 'open_circuit',\n           'short', 'spur', 'spurious_copper']\nyolo_labels = convert_to_yolo_labels(annot_df_resized, classes)\n","metadata":{"id":"orcXUURcCb53"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_images_and_labels(images_dir, labels, output_dir, train_split=0.95, val_split=0.05):\n    # os.makedirs(output_dir, exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'images/test'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'labels/test'), exist_ok=True)\n\n    # Group labels by image filename\n    image_labels = {}\n    for label in labels:\n        filename, class_index, x_center, y_center, bbox_width, bbox_height = label\n        if filename not in image_labels:\n            image_labels[filename] = []\n        image_labels[filename].append(label)\n\n    # Shuffle the image filenames\n    image_filenames = list(image_labels.keys())\n    random.shuffle(image_filenames)\n\n    # Split the dataset\n    num_images = len(image_filenames)\n    num_train = int(num_images * train_split)\n    num_val = int(num_images * val_split)\n\n    train_filenames = image_filenames[:num_train]\n    val_filenames = image_filenames[num_train:num_train + num_val]\n    test_filenames = image_filenames[num_train + num_val:]\n\n    # Write train, val, test images and labels\n    for dataset, filenames in [('train', train_filenames), ('val', val_filenames), ('test', test_filenames)]:\n        for filename in filenames:\n            labels = image_labels[filename]\n            with open(os.path.join(output_dir, f'labels/{dataset}/{os.path.splitext(filename)[0]}.txt'), 'a') as label_file:\n                for label in labels:\n                    _, class_index, x_center, y_center, bbox_width, bbox_height = label\n                    label_file.write(f\"{class_index} {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n            # Copy images to corresponding folders\n            shutil.copy(os.path.join(images_dir, filename), os.path.join(output_dir, f'images/{dataset}/{filename}'))\n\nsplit_images_and_labels(resized_img_dir, yolo_labels, output_dir)","metadata":{"id":"Q7KFU_EsGHRZ"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# K-Fold Cross Validation","metadata":{"id":"FQvyo42TWZHQ"}},{"cell_type":"code","source":"dataset_path = Path(output_dir)\nlabels = sorted(dataset_path.rglob(\"*labels/train/*.txt\")) # all data in 'labels'","metadata":{"id":"mr8v9IWIWYjE"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cls_idx = list(range(len(classes)))\nprint(list(zip(classes, cls_idx)))","metadata":{"id":"MxguULP3X3Bf","outputId":"2ea13c95-26a8-49c3-839c-56d391b3b7cf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"indx = [l.stem for l in labels] # uses base filename as ID (no extension)\nlabels_df = pd.DataFrame([], columns=cls_idx, index=indx)","metadata":{"id":"bUCCm7K5X-bU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for label in labels:\n    lbl_counter = Counter()\n\n    with open(label,'r') as lf:\n        lines = lf.readlines()\n\n    for l in lines:\n        # classes for YOLO label uses integer at first position of each line\n        lbl_counter[int(l.split(' ')[0])] += 1\n\n    labels_df.loc[label.stem] = lbl_counter\n\nlabels_df = labels_df.fillna(0.0) # replace `nan` values with `0.0`\nlabels_df.head()","metadata":{"id":"TNMwnGbeYEbP","outputId":"88ce498c-08c0-46db-baa1-329e0e463277"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ksplit = 3\nkf = KFold(n_splits=ksplit, shuffle=True, random_state=20)   # setting random_state for repeatable results\n\nkfolds = list(kf.split(labels_df))","metadata":{"id":"vp4GxrGxYJET"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folds = [f'split_{n}' for n in range(1, ksplit + 1)]\nfolds_df = pd.DataFrame(index=indx, columns=folds)\n\nfor idx, (train, val) in enumerate(kfolds, start=1):\n    folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'train'\n    folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'val'","metadata":{"id":"pg4gW0QSYWVQ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n\nfor n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n    train_totals = labels_df.iloc[train_indices].sum()\n    val_totals = labels_df.iloc[val_indices].sum()\n\n    # To avoid division by zero, we add a small value (1E-7) to the denominator\n    ratio = val_totals / (train_totals + 1E-7)\n    fold_lbl_distrb.loc[f'split_{n}'] = ratio\n\nfold_lbl_distrb","metadata":{"id":"eyAgw0nnYX0s","outputId":"d92ba636-fcf6-45bc-d003-56be3b0d34dc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize a list to store image file paths\nimages = sorted(dataset_path.rglob(\"*images/train/*.jpg\"))\n\n# Create the necessary directories and dataset YAML files (unchanged)\nsave_path = Path(dataset_path / f'{ksplit}fold_crossval')\nsave_path.mkdir(parents=True, exist_ok=True)\nds_yamls = []\n\nfor split in folds_df.columns:\n    # Create directories\n    split_dir = save_path / split\n    split_dir.mkdir(parents=True, exist_ok=True)\n    (split_dir / 'train' / 'images').mkdir(parents=True, exist_ok=True)\n    (split_dir / 'train' / 'labels').mkdir(parents=True, exist_ok=True)\n    (split_dir / 'val' / 'images').mkdir(parents=True, exist_ok=True)\n    (split_dir / 'val' / 'labels').mkdir(parents=True, exist_ok=True)\n\n    # Create dataset YAML files\n    dataset_yaml = split_dir / f'{split}_dataset.yaml'\n    ds_yamls.append(dataset_yaml)\n\n    with open(dataset_yaml, 'w') as ds_y:\n        yaml.safe_dump({\n            'path': split_dir.as_posix(),\n            'train': 'train',\n            'val': 'val',\n            'names': classes\n        }, ds_y)","metadata":{"id":"bsuzSzBkYezu"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image, label in zip(images, labels):\n    for split, k_split in folds_df.loc[image.stem].items():\n        # Destination directory\n        img_to_path = save_path / split / k_split / 'images'\n        lbl_to_path = save_path / split / k_split / 'labels'\n\n        # Copy image and label files to new directory\n        shutil.copy(image, img_to_path / image.name)\n        shutil.copy(label, lbl_to_path / label.name)","metadata":{"id":"NMka5WLoYzE-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folds_df.to_csv(save_path / \"kfold_datasplit.csv\")\nfold_lbl_distrb.to_csv(save_path / \"kfold_label_distribution.csv\")","metadata":{"id":"6cxBU0VBY_ub"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Training","metadata":{"id":"qVtG7KOwb4uB"}},{"cell_type":"code","source":"model = YOLO('yolov8s.pt')\nresults = {}\n\n# Additional arguments here\nbatch = 16\nproject = 'pcb'\nepochs = 180\nimgsz=640\nsave_period=1\nverbose=True\n# box=6.0 # Weight of the box loss component in the loss function\n# cls = 2.0 # Weight of the classification loss in the total loss function\nmixup = 0.3 # Blends two images and their labels, creating a composite image\n\nfor k in range(ksplit):\n    dataset_yaml = ds_yamls[k]\n    model.train(data=dataset_yaml,\n                epochs=epochs,\n                batch=batch,\n                lr0=0.001,\n                lrf=0.0001,\n                imgsz=imgsz,\n                save_period=save_period,\n                verbose=verbose,\n                project=project,\n                mixup=mixup)\n    results[k] = model.metrics  # save output metrics for further analysis","metadata":{"id":"tErueJdsb3uQ","outputId":"c58a0331-f2a6-479b-8f18-7fe21870873f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{"id":"nMHeNByV8JKv"}},{"cell_type":"code","source":"model = YOLO('yolov8s.pt')\n\n# Additional arguments here\nbatch = 16\nproject = 'pcb'\nepochs = 180\nimgsz=640\nsave_period=1\nverbose=True\n# box=6.0 # Weight of the box loss component in the loss function\n# cls = 2.0 # Weight of the classification loss in the total loss function\nmixup = 0.3 # Blends two images and their labels, creating a composite image\n\nall_data_yaml = f\"\"\"\npath: {output_dir}\ntrain: images/train\nval: images/val\n\nnames:\n    0: missing_hole\n    1: mouse_bite\n    2: open_circuit\n    3: short\n    4: spur\n    5: spurious_copper\n\"\"\"\n\ndata_path = os.path.join(root_dir, 'data.yaml')\n\nwith open(data_path, 'w') as f:\n    f.write(all_data_yaml)\n\nresult = model.train(data=data_path,\n                     epochs=epochs,\n                     batch=batch,\n                     lr0=0.001,\n                     lrf=0.0001,\n                     imgsz=imgsz,\n                     save_period=save_period,\n                     verbose=verbose,\n                     project=project,\n                     mixup=mixup)","metadata":{"id":"DUzoujU_L2WI","outputId":"f1feb7ba-7a83-4d69-8a60-619ce57747c6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_dir = '/content/pcb/train4'\ndest_results_dir = os.path.join(root_dir, 'results')\n\nshutil.copytree(results_dir, dest_results_dir)","metadata":{"id":"XsprK7peOHFE","outputId":"c150eb69-901b-499a-b974-6bb97da2981a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.read_csv(os.path.join(dest_results_dir, 'results.csv'))\nresults_df.columns = results_df.columns.str.strip()\nresults_df = results_df.apply(pd.to_numeric, errors='coerce').dropna()\nresults_df.head()","metadata":{"id":"wzL0ck_4mIER","outputId":"6a52923b-c355-44a7-b101-f89967f85acb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = results_df['epoch']\ntrain_box_loss = results_df['train/box_loss']\nval_box_loss = results_df['val/box_loss']\ntrain_cls_loss = results_df['train/cls_loss']\nval_cls_loss = results_df['val/cls_loss']\ntrain_dfl_loss = results_df['train/dfl_loss']\nval_dfl_loss = results_df['val/dfl_loss']\n\n# Create a figure with three subplots\nfig, axs = plt.subplots(1, 3, figsize=(18, 6))\n\n# Plot box loss\naxs[0].plot(epochs, train_box_loss, label='Train Box Loss', color='blue')\naxs[0].plot(epochs, val_box_loss, label='Validation Box Loss', color='orange')\naxs[0].set_title('Box Loss')\naxs[0].set_xlabel('Epoch')\naxs[0].set_ylabel('Loss')\naxs[0].legend()\naxs[0].grid(True)\n\n# Plot cls loss\naxs[1].plot(epochs, train_cls_loss, label='Train Cls Loss', color='blue')\naxs[1].plot(epochs, val_cls_loss, label='Validation Cls Loss', color='orange')\naxs[1].set_title('Class Loss')\naxs[1].set_xlabel('Epoch')\naxs[1].set_ylabel('Loss')\naxs[1].legend()\naxs[1].grid(True)\n\n# Plot dfl loss\naxs[2].plot(epochs, train_dfl_loss, label='Train Dfl Loss', color='blue')\naxs[2].plot(epochs, val_dfl_loss, label='Validation Dfl Loss', color='orange')\naxs[2].set_title('Distribution Focal Loss')\naxs[2].set_xlabel('Epoch')\naxs[2].set_ylabel('Loss')\naxs[2].legend()\naxs[2].grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"-HaskkdzC2g1","outputId":"ad0783f5-da68-4404-c5d7-5b081100e9d1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predict on test data","metadata":{"id":"z0dZZD_LqbbF"}},{"cell_type":"code","source":"best_model_path = os.path.join(dest_results_dir, 'weights/best.pt')\nmodel = YOLO(best_model_path)\n\ntest_data_dir = os.path.join(output_dir, 'images/val')\nmetrics = model(source=test_data_dir, imgsz=640, conf=0.25, save=True, save_txt=True, save_conf=True)","metadata":{"id":"IJAimwD7qbLQ","outputId":"c2b43f8a-af11-4d26-8e0f-bdbd2a5e66c5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_dir = '/content/runs/detect/predict'\ndest_predict_dir = os.path.join(root_dir, 'results/predict')\n\nshutil.copytree(predict_dir, dest_predict_dir)","metadata":{"id":"ceuNG333jmy0","outputId":"394e9a7a-8eb5-4b78-83f6-34b5c3b4ad76"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def yolo_to_original_annot(image_name, yolo_labels, annot_df, classes):\n    original_annot = []\n\n    for yolo_label in yolo_labels:\n        # Extract original width and height from annotation DataFrame\n        original_size = annot_df.loc[annot_df['filename'] == image_name, ['width', 'height']].iloc[0]\n        original_width, original_height = original_size['width'], original_size['height']\n\n        # Extract YOLO label components\n        class_index, x_center, y_center, bbox_width, bbox_height, confidence = yolo_label\n\n        # Scale bounding box coordinates and dimensions to original size\n        original_x_center = x_center * original_width\n        original_y_center = y_center * original_height\n        original_bbox_width = bbox_width * original_width\n        original_bbox_height = bbox_height * original_height\n\n        # Calculate original bounding box coordinates\n        original_x_min = original_x_center - original_bbox_width / 2\n        original_y_min = original_y_center - original_bbox_height / 2\n        original_x_max = original_x_center + original_bbox_width / 2\n        original_y_max = original_y_center + original_bbox_height / 2\n\n        # Append original annotation to list\n        original_annot.append({\n            'filename': image_name,\n            'width': int(original_width),\n            'height': int(original_height),\n            'class': classes[int(class_index)],\n            'xmin': int(original_x_min),\n            'ymin': int(original_y_min),\n            'xmax': int(original_x_max),\n            'ymax': int(original_y_max),\n            'confidence': confidence\n        })\n\n    return pd.DataFrame(original_annot)","metadata":{"id":"uvbFG1PXt7dt"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_yolo_labels_from_file(file_path):\n    labels = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            values = line.strip().split()\n            values = [float(value) for value in values]\n            labels.append(values)\n    return labels\n\nfile_path = os.path.join(dest_predict_dir, 'labels/12_spurious_copper_10.txt')\nyolo_labels = read_yolo_labels_from_file(file_path)\nyolo_labels","metadata":{"id":"a9HGCGx-YAvJ","outputId":"0cdb1350-2485-40f8-9e9f-d1c95a801eff"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_annot_df = yolo_to_original_annot('12_spurious_copper_10.jpg', yolo_labels, annot_df, classes)\npred_annot_df.head()","metadata":{"id":"4f0S8AGpZbyb","outputId":"7010b266-0f01-4ee8-b36b-200e6752f4d8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_annotations('12_spurious_copper_10.jpg', images_dir, pred_annot_df, is_subfolder=True);","metadata":{"id":"qBNL6gdVj14w","outputId":"eac0ac95-bacd-465f-e737-ee4877ce7b9d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_annotations('12_spurious_copper_10.jpg', images_dir, annot_df, is_subfolder=True);","metadata":{"id":"zNDoWxRvkXdp","outputId":"0dcb7c97-56bd-4be6-d293-74f7ce947bed"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.export()","metadata":{"id":"r5C3i7e1FHww","outputId":"984c8610-f7bc-4d80-c133-fcab3d1d6fc2"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_img_dir = os.path.join(root_dir, 'custom_images')\nresized_custom_img_dir = os.path.join(custom_img_dir, 'resized')\nresize_images(custom_img_dir, resized_custom_img_dir)","metadata":{"id":"IlZkiiYVFAA0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(best_model_path)\n\nimage_path = os.path.join(resized_custom_img_dir, '01.jpg')\nresult_custom = model(image_path, imgsz=640, conf=0.25, save=True, save_txt=True, save_conf=True)","metadata":{"id":"fpY3xBk85YTK","outputId":"5fcd61a1-1e64-43f0-e9ce-1ed7c5645c2f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_dir = '/content/runs/detect/predict2'\ndest_custom_predict_dir = os.path.join(custom_img_dir, 'results/predict')\n\nshutil.copytree(predict_dir, dest_custom_predict_dir)","metadata":{"id":"EZdTwTBhF2CD","outputId":"400129aa-3527-4b7b-fc18-19a9023155e7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"1DWfVvbwGR4e"},"outputs":[],"execution_count":null}]}